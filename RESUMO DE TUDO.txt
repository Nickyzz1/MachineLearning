====== MACHINE LEARNING =========================================================

Machine Learning, ou Aprendizado de Máquina, são algoritmos que usam estatística e outros conceitos
matemáticos para fazer com que seja possível aprender os padrões e retirar informações de dados fornecidos

Salvar o modelo para não precisar treinar de novo;
pag 47;

====== REGRESSÃO #

REGRESSÃO = PREVER VALORES. EX: QUANTO ESSA CASA VAI VALER?

MIN_SAMPLES : É o número mínimo de amostras que deve existir em cada folha

FEATURE : É UMA COLUNA

== é o mesmo peso para todos os elementos de uma coluna, pA para coluna A, pB para coluna B, etc..

== regulador evita que o W exploda

== formuka do w SGD

	wk -= alfa + de/dwx

== PRINCIPIOS DA IA ==

- Formula do erro:

	E(w, b) = somatória (vetorxi * vetorW + b - y)² + [regulador : parametro passsado [w] -> módulo de w ]

		4 - 16
		4 - 16
		5 - 25
		erro global = 16 + 16 + 25 = 57

-  OBJETIVO: Achar o w e o beta para que o erro seja mínimo;


	derivadaE/derivadaWk = 2 * Somatória(vetorX * vetorW + beta - y) * XiK  => descobrir a derivada do erro, se encontrar onde a derivada é
	zero vc acha o ponto mínimo do erro;
	k = coluna;
	XiK = é o a matriz da coluna e linha onde o peso que se leva em consideração é usado, o vetor x é uma lista

	com regulador:

	- DerivadaE/derivadaWk = 2 * Somatória(vetorXi * vetorW + beta - y) * XiK + [isso é um regulador:]2pWk ===> subtrair a derivada te leva pro ponto zero pois a 	derivada vai ser negativa e ele vai andar um pouquinho par baixo

	vetorY = 2 * Somatória(vetorXi0 * W0 + xi1 * W1 + xi2 * w2 + Beta)


=== separar ados em y de treino e x de treino; y de teste e x de teste

=== atv para printar : quando terminar uam época vc vai printar o calculo do erro de treinoe  o erro de teste e o numero da épocA = Digamos que vc tem 300 dados
quando vc rodar vai ler do 0 ao 100 e treinar, depois do 101 a 200, depois do 201 ao 300, ai acabou uamépoca, depois vcc faz td de novo para diminuir o erro 

====== TIPOS DE PROBLEMAS ========================================================

	- OVERFITING: o modelo "aprende demais" a respeito dos dados
	aprendendo seus ruídos e especificidades que podem ser característicos apenas dos dados de
	treinamento mas não dos de testes. Isso não parece ruim mas na verdade é, isso significa que
	o modelo será incapaz de lidar com novos e diferentes dados do problema.

	### overfiting se mede vendo a precisão dos dados de treino e de teste ###

	RESOLVER : AUMENTA O DEPTH E AUMENTA O MINSAMPLES(AUMENTAR PARÂMETROS)

	- UNDERFITING: O algoritmo tem resultados ruins, ou seja, baixa precisão, vai mal tanto nos
	dados de teste quanto nos dados de treino.


====== CLASSES/CLASSIFICAÇÃO APRENDIZADO NN SUPERVISIONADO ======================

    - Clusterização/Agrupamento: Não conhecemos as classes mas queremos agregá-los, por isso
	separamos os dados em grupos/conjuntos. Por exemplo, temos dados de consumidores de um
	mercado. Não conhecemos os tipos de consumidores mas podemos tentar agrupá-los e descobrir que existem perfis de usuários que se comportam de forma igual.
	- CLASSE É CADA UM DOS CASOS. EX: CLASSA DOENÇA A, CLASSE DOENÇA B E CLASSE SADIO

====== TREINAMENTO E VALIDAÇÃO =================================================

1 - Separamos os dados em teste e treino;
2 - Treinamos o modelo sobre os dados de teste;
3 - Calculámos métricas de desempenho para avaliarmos se o modelo está bom ou o que
precisamos mudar nele.

====== DECISION TREE ==========================================================

====== ÍNDICE DE GINI #

- ALGORÍTIMO: PERCEBE A MELHOR FORMA DE DIVIDIR OS DADOS PARA MONTAR A ÁRVORE =>
	ELE VÊ TODAS AS DIVISÕES POSSÍVEIS DEPOIS COMPARA QUAL DEU O INDICE DE GINE MAIS PERTO OU DE 1 OU DE 0
	EXEMPLO: DE DÁ 40% SIGNIFICA QUE 4O% FAZ A E OS OUTROS 60% FAZ B, NÃO ESTA MUITO PRECISO, AGORA SE 90% FAZ A E SÓ 10% FAZ B É MAIS PRECISO, 90% É BEM MAIS

- SEPARA OS GRUPOS MAIS OMOGÊNEOS

- SE O INDICE DE GINI FOR ALTO NÃO É BOM DIVIDIR OS DADOS ALÍ

===== GANHANDO PRECISÃO

- Depth infinito e minsamples é 1, ele vai achar todas as possibilidades do minsamples. Porém, quanto mais específico fica mais overfiting(ruído);

-- valor mínimo d euma função é tirar a derivada(é o angulo da reta) e iogualar a zero

======================================= Resolvendo Regressão e Classificação =======================================

vetor : pq é uma lista;

vetorX(linha que está) * vetorPeso(valor aleatório) + b(valor aleatório)

# Beta e peso variam #

=== Como ajustar esses valores : definir uma função erro(w, b); (vetorX(linha onde está) + vetorPeso + b - posiçãodacolunaquequerdescobrir)² ==> minimizar o erro é o 	objetivo, isso é treinar o algoritimo; depoise dessa equeção vcc soma todos os resultados que isso deu para cada item; b e w são números aleatórios; quanto mais perto 	da realidade mais bem treinada sua IA está; ==> objetivo centrral, achar os valores de omega e beta poara qual o erro é mínimo;

## Equação para prever o valor: erro: x(linha dos dados) * w(peso)  b(beta)

para achar beta precisa dos valores que deixem a equação a seguir igual a zero:

derivada do erro:
de/db = 2 * somaDeTodosOsResultadosNoParenteses(vetorX + vetorW + b - y) = 0
=> somatória vetorX + w + somatóriaB - somatóriaX = 0;
x * w + nb - y = 0
b = (y - xw) /n
w = xy - somatóriaY * todosOsDadosComoMatrizX / x² - somatóriaX * todosOsDadosComoMatrizX

====== Lasso regression #

====== STOCHASTIC GARDIENT DESCENT #


== GRADIENT DESCENDENT

- Derivada é negativa quando está caindo, o contrário é verdadeiro
- sua posiçõa atual x é modificada assim: x = x - (alfa * defivada) // o x vai aumnetra pois vc está subtraindo uma valor negativo
diminui a distancia do x até o valor mínimo
- alfa é o parâmetro de aprendizagem, quanto mais baixo mais demora ele andar(vai devagar nos "passos")
- se o alfa for grand eel pode estourar

== STOCHASTIC GRADIENT DESCENDENT

Olha de poquinho em poquinho os dados para achar o ponto mínimo, vai mais rápido que o gradient descendent pois este olha todos; 
Ele é vcai corretamente porém vai mais rápido; Sempre pegar x dados diferentes para analisar;
-- quanto maior o alfa menos passos precisando e mais rápido é
-- se o alfa for muito grande o algorítimo fica instável e nunca chega, se seu algoritmo está muito lento o alfa deve ser maior
-- rodar e pararf rápido para ver como está indo o progresso do algoritmo com o alfa atual

O beta muda assim : b = b - alfa * 2 * soamtória(x * w + b - y)
=> se for o stochast ele não vai fazer em todos os dados, mas sim num pedaço

== problema do mínimo: rodar varias vezes para achar o ponto mínimo certo, se rodar muitas evzes e não houver nenhum outro valor menor encontrado como valor mínimo
você achou o correto

alfa = 0,1 ==> palpite idal

w = w - alfa * 2 * somatória(y * w + b - y)x;

=======================


== ELASTIC NET


Erro (ou Função de Custo): O cálculo do erro em problemas de aprendizado de máquina é uma medida de quão bem o modelo está fazendo previsões em relação aos resultados reais. Quanto menor o erro, melhor o modelo.

Derivada do Erro (Gradiente): O gradiente (ou derivada) do erro com relação aos pesos é utilizado para entender como o erro muda quando você ajusta os pesos. Ele indica a direção e a magnitude da mudança necessária para minimizar o erro.

Gradiente Descendente: Esse é o processo de otimização mais comum. O gradiente nos diz como atualizar os pesos (seja para aumentar ou diminuir) para reduzir o erro. A ideia é mover-se na direção oposta ao gradiente para minimizar o erro.


O valor de -24975.595346540213 indica a taxa de variação negativa do erro em relação ao peso que você modificou (no índice que você escolheu).
Como é negativo, isso significa que, se você aumentar o peso específico, o erro diminui. Em termos de gradiente descendente, isso indica que você deve aumentar o valor do peso para reduzir o erro.

O valor negativo de -24975.595346540213 sugere que, para melhorar o modelo (ou seja, reduzir o erro), você deve aumentar o peso em questão.



