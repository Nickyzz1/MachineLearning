{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reorganização concluída!\n"
     ]
    }
   ],
   "source": [
    "#heheheh\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Caminho para a pasta com as imagens\n",
    "dataset_path = 'flowers'\n",
    "# Caminho para onde as subpastas serão criadas (opcional, se quiser em outro local)\n",
    "output_path = 'flowers_reorganized'  # Modifique conforme necessário\n",
    "\n",
    "# Crie a pasta de saída se ela não existir\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Lista de arquivos na pasta\n",
    "image_files = os.listdir(dataset_path)\n",
    "\n",
    "# Criação das subpastas e movimentação dos arquivos\n",
    "for image_file in image_files:\n",
    "    # Extrai a classe do nome do arquivo\n",
    "    class_name = image_file.split('_')[0]\n",
    "    \n",
    "    # Cria a pasta da classe se ela não existir\n",
    "    class_folder = os.path.join(output_path, class_name)\n",
    "    if not os.path.exists(class_folder):\n",
    "        os.makedirs(class_folder)\n",
    "    \n",
    "    # Move o arquivo para a pasta correspondente\n",
    "    src_path = os.path.join(dataset_path, image_file)\n",
    "    dst_path = os.path.join(class_folder, image_file)\n",
    "    \n",
    "    # Move o arquivo para a nova subpasta\n",
    "    shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Reorganização concluída!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, activations, optimizers, utils, losses, initializers, metrics, callbacks\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32 # tamanho da separação do sgd, cada vez que roda ele atualiza os pessos da rede, entt ele vai atualizar os pesos 32 vezes, mtt pequeno é mais rápido mas instável\n",
    "patience = 5 # quanto que o earlystop vai esperar para para, nesse caso são 5 epochs\n",
    "learning_rate = 0.001 # alfa do SGD\n",
    "model_path = 'kaggle/checkpoints/model.keras' # onde ele vai salvar o modelo, o 'dump'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10  # Define corretamente o número de classes\n",
    "\n",
    "model = models.Sequential([\n",
    "    # diminuir para fazer covuluções sem dar milhões de parâmetros\n",
    "    layers.Resizing(56, 56), # colocando todas as imagens do mesmo tamanho, nn corta a imagem apenas diminui a resolução    \n",
    "    layers.Rescaling(1.0/255), # deixar todos os valores dos pixels entre 0 e 1\n",
    "    layers.RandomRotation((-0.2 , 0.2)), # leve rotação para cada imagem, rotacionar deixa mais lento mas aumenta a precisão\n",
    "\n",
    "\n",
    "    # covolucao\n",
    "    layers.Conv2D(32, (3, 3), # 32 filtros 3 por 3, tenho 32 imagens 54 por 54\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal() # valor aleatório com distribuição normal \n",
    "    ),\n",
    "    \n",
    "    layers.MaxPooling2D((2, 2)), # 32 imagens 27 por 27, pooling pega cada 4 quadradinhos e pega o valor máximo de cada quadradinho, isso diminui a lentidão\n",
    "\n",
    "    layers.Conv2D(64, (4, 4),\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal()\n",
    "    ),\n",
    "                  \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "                  \n",
    "    layers.Flatten(), # vai pegar tds as imagens 9 x 8 e tranformar num vetor gigante\n",
    "\n",
    "    layers.Dropout(0.2), # desativa 20% dos dados na camada\n",
    "                  \n",
    "    layers.Dense(128, \n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal()\n",
    "    ),\n",
    "                  \n",
    "    layers.Dense(64, \n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal()\n",
    "    ),\n",
    "\n",
    "    layers.Dense(num_classes, activation='softmax')  # Ajustado para múltiplas classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizers.Adam( # adam é um algoritmo keras\n",
    "        learning_rate = learning_rate\n",
    "    ),\n",
    "    # loss=losses.CategoricalCrossentropy(), # mais de uma classe, quando nn é um int a classe\n",
    "    loss=losses.SparseCategoricalCrossentropy(), # quando é int a classe\n",
    "    # metrics = [metrics.BinaryAccuracy(), metrics.Precision(), metrics.Recall() ] # para uma classe só, 1 ou 0\n",
    "    metrics=['accuracy']  # Usa accuracy normal para multiclasse\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 733 files belonging to 10 classes.\n",
      "Using 587 files for training.\n",
      "Found 733 files belonging to 10 classes.\n",
      "Using 146 files for validation.\n",
      "['bougainvillea', 'daisies', 'garden', 'gardenias', 'hibiscus', 'hydrangeas', 'lilies', 'orchids', 'peonies', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "train = utils.image_dataset_from_directory(\n",
    "    output_path,\n",
    "    validation_split = 0.2,\n",
    "    subset= 'training',\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    image_size=(244,244),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test = utils.image_dataset_from_directory(\n",
    "    output_path,\n",
    "    validation_split = 0.2,\n",
    "    subset= 'validation',\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    image_size=(244,244),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "print(train.class_names)\n",
    "\n",
    "# Se as imagens forem RGB, o formato precisa ser (batch_size, altura, largura, 3). Para conferir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.1386 - loss: 2.2751 - val_accuracy: 0.3425 - val_loss: 1.9819\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.2906 - loss: 1.9286 - val_accuracy: 0.2877 - val_loss: 1.8758\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.3520 - loss: 1.7667 - val_accuracy: 0.2260 - val_loss: 2.0255\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.3528 - loss: 1.7664 - val_accuracy: 0.3767 - val_loss: 1.6772\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.4365 - loss: 1.5977 - val_accuracy: 0.5000 - val_loss: 1.5866\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4862 - loss: 1.4597 - val_accuracy: 0.3904 - val_loss: 1.7534\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5117 - loss: 1.3978 - val_accuracy: 0.4521 - val_loss: 1.6529\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5063 - loss: 1.4236 - val_accuracy: 0.4521 - val_loss: 1.5851\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5436 - loss: 1.3198 - val_accuracy: 0.4726 - val_loss: 1.5466\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.5850 - loss: 1.2569 - val_accuracy: 0.4863 - val_loss: 1.4201\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5896 - loss: 1.1987 - val_accuracy: 0.4726 - val_loss: 1.4555\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.6121 - loss: 1.1385 - val_accuracy: 0.5274 - val_loss: 1.5147\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.6454 - loss: 1.0721 - val_accuracy: 0.5205 - val_loss: 1.3848\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6591 - loss: 0.9995 - val_accuracy: 0.5000 - val_loss: 1.5488\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.6806 - loss: 0.9590 - val_accuracy: 0.5274 - val_loss: 1.4469\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6857 - loss: 0.9058 - val_accuracy: 0.5616 - val_loss: 1.4909\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6922 - loss: 0.8590 - val_accuracy: 0.5548 - val_loss: 1.4796\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.7685 - loss: 0.7268 - val_accuracy: 0.5548 - val_loss: 1.5557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x206e4222120>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data = test,\n",
    "    epochs = epochs,\n",
    "    callbacks = [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience\n",
    "        )\n",
    "        # callbacks.ModelCheckpoint(\n",
    "        #     filepath = model_path,\n",
    "        #     save_weights_only = False,\n",
    "        #     monitor = 'loss',\n",
    "        #     mode = 'min',\n",
    "        #     save_best_only = True\n",
    "        # )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
