{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heheheh\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "path_train = '/kaggle/input/melanoma-cancer-dataset/train/'\n",
    "path_test = '/kaggle/input/melanoma-cancer-dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tensorflow.keras import models, layers, activations, optimizers, utils, losses, initializers, metrics, callbacks\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32 # tamanho da separação do sgd, cada vez que roda ele atualiza os pessos da rede, entt ele vai atualizar os pesos 32 vezes, mtt pequeno é mais rápido mas instável\n",
    "patience = 5 # quanto que o earlystop vai esperar para para, nesse caso são 5 epochs\n",
    "learning_rate = 0.001 # alfa do SGD\n",
    "model_path = 'kaggle/checkpoints/model.keras' # onde ele vai salvar o modelo, o 'dump'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    # diminuir para fazer covuluções sem dar milhões de parâmetros\n",
    "    layers.Resizing(56, 56), # colocando todas as imagens do mesmo tamanho, nn corta a imagem apenas diminui a resolução    \n",
    "    layers.Rescaling(1.0/255), # deixar todos os valores dos pixels entre 0 e 1\n",
    "    layers.RandomRotation((-0.2 , 0.2)), # leve rotação para cada imagem, rotacionar deixa mais lento mas aumenta a precisão\n",
    "\n",
    "\n",
    "    # covolucao\n",
    "    layers.Conv2D(32, (3, 3), # 32 filtros 3 por 3, tenho 32 imagens 54 por 54\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal() # valor aleatório com distribuição normal \n",
    "    ),\n",
    "    \n",
    "    layers.MaxPooling2D((2, 2)), # 32 imagens 27 por 27, pooling pega cada 4 quadradinhos e pega o valor máximo de cada quadradinho, isso diminui a lentidão\n",
    "\n",
    "    layers.Conv2D(64, (4, 4),\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal()\n",
    "    ),\n",
    "                  \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "                  \n",
    "    layers.Flatten(), # vai pegar tds as imagens 9 x 8 e tranformar num vetor gigante\n",
    "\n",
    "    layers.Dropout(0.2), # desativa 20% dos dados na camada\n",
    "                  \n",
    "    layers.Dense(128, \n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal()\n",
    "    ),\n",
    "                  \n",
    "    layers.Dense(64, \n",
    "        activation = 'relu',\n",
    "        kernel_initializer = initializers.RandomNormal()\n",
    "    ),\n",
    "\n",
    "    layers.Dense(1, \n",
    "        activation = 'sigmoid',\n",
    "        kernel_initializer = initializers.RandomNormal()\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizers.Adam( # adam é um algoritmo keras\n",
    "        learning_rate = learning_rate\n",
    "    ),\n",
    "    loss = losses.BinaryCrossentropy(),\n",
    "    metrics = [metrics.BinaryAccuracy(), metrics.Precision(), metrics.Recall() ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = utils.image_dataset_from_directory(\n",
    "    path_train,\n",
    "    # validation_split = 0.2,\n",
    "    # subset= 'training',\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    image_size=(244,244),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test = utils.image_dataset_from_directory(\n",
    "    path_test,\n",
    "    # validation_split = 0.2,\n",
    "    # subset= 'validation',\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    image_size=(244,244),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train,\n",
    "    validation_data = test,\n",
    "    epochs = epochs,\n",
    "    callbacks = [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience\n",
    "        )\n",
    "        # callbacks.ModelCheckpoint(\n",
    "        #     filepath = model_path,\n",
    "        #     save_weights_only = False,\n",
    "        #     monitor = 'loss',\n",
    "        #     mode = 'min',\n",
    "        #     save_best_only = True\n",
    "        # )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
