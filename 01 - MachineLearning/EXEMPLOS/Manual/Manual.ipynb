{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Gerando dados sintéticos\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Dividindo em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adicionando bias\n",
    "X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "# Implementação da Elastic Net manualmente\n",
    "def elastic_net(X, y, alpha=0.1, l1_ratio=0.5, lr=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    theta = np.random.randn(n, 1)\n",
    "    for epoch in range(epochs):\n",
    "        gradients = (2/m) * X.T.dot(X.dot(theta) - y) + alpha * (\n",
    "            l1_ratio * np.sign(theta) + (1 - l1_ratio) * theta)\n",
    "        theta -= lr * gradients\n",
    "    return theta\n",
    "\n",
    "# Treinando modelo\n",
    "elastic_theta = elastic_net(X_train_b, y_train)\n",
    "\n",
    "# Predições\n",
    "y_train_pred = X_train_b.dot(elastic_theta)\n",
    "y_test_pred = X_test_b.dot(elastic_theta)\n",
    "\n",
    "# Erro\n",
    "train_error = np.mean((y_train_pred - y_train) ** 2)\n",
    "test_error = np.mean((y_test_pred - y_test) ** 2)\n",
    "\n",
    "print(\"Erro de Treino Elastic Net:\", train_error)\n",
    "print(\"Erro de Teste Elastic Net:\", test_error)\n",
    "\n",
    "# Plotando resultados\n",
    "plt.scatter(X_train, y_train, label=\"Treino\")\n",
    "plt.scatter(X_test, y_test, label=\"Teste\", color='red')\n",
    "plt.plot(X_train, y_train_pred, color='blue', linewidth=2, label=\"Elastic Net\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Elastic Net Manual\")\n",
    "plt.show()\n",
    "\n",
    "# Implementação manual da Decision Tree\n",
    "class DecisionTree:\n",
    "    def __init__(self, depth=3):\n",
    "        self.depth = depth\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth >= self.depth or len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        \n",
    "        return (best_feature, best_threshold, left_subtree, right_subtree)\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature, best_threshold, best_loss = None, None, float('inf')\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feature] <= threshold\n",
    "                right_mask = ~left_mask\n",
    "                \n",
    "                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "                    continue\n",
    "                \n",
    "                left_loss = np.var(y[left_mask]) * np.sum(left_mask)\n",
    "                right_loss = np.var(y[right_mask]) * np.sum(right_mask)\n",
    "                loss = left_loss + right_loss\n",
    "                \n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
    "    \n",
    "    def _predict_one(self, x, node):\n",
    "        if not isinstance(node, tuple):\n",
    "            return node\n",
    "        feature, threshold, left, right = node\n",
    "        return self._predict_one(x, left) if x[feature] <= threshold else self._predict_one(x, right)\n",
    "\n",
    "# Treinando a árvore\n",
    "X_train_tree = X_train.reshape(-1, 1)\n",
    "y_train_tree = y_train.ravel()\n",
    "dt = DecisionTree(depth=3)\n",
    "dt.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "# Predições\n",
    "y_train_pred_tree = dt.predict(X_train_tree)\n",
    "y_test_pred_tree = dt.predict(X_test)\n",
    "\n",
    "# Erro\n",
    "train_error_tree = np.mean((y_train_pred_tree - y_train_tree) ** 2)\n",
    "test_error_tree = np.mean((y_test_pred_tree - y_test.ravel()) ** 2)\n",
    "\n",
    "print(\"Erro de Treino Decision Tree:\", train_error_tree)\n",
    "print(\"Erro de Teste Decision Tree:\", test_error_tree)\n",
    "\n",
    "# Plotando resultados\n",
    "plt.scatter(X_train, y_train, label=\"Treino\")\n",
    "plt.scatter(X_test, y_test, label=\"Teste\", color='red')\n",
    "plt.scatter(X_train, y_train_pred_tree, color='blue', label=\"Decision Tree\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Decision Tree Manual\")\n",
    "plt.show()\n",
    "\n",
    "# Implementação manual do SVM (SVC - Kernel Linear)\n",
    "def hinge_loss(X, y, w, b, C):\n",
    "    margins = 1 - y * (X.dot(w) + b)\n",
    "    loss = np.maximum(0, margins)\n",
    "    return 0.5 * np.sum(w ** 2) + C * np.sum(loss)\n",
    "\n",
    "def sgd_svm(X, y, C=1.0, lr=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    w = np.zeros(n)\n",
    "    b = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(m):\n",
    "            if y[i] * (X[i].dot(w) + b) < 1:\n",
    "                w -= lr * (w - C * y[i] * X[i])\n",
    "                b -= lr * (-C * y[i])\n",
    "            else:\n",
    "                w -= lr * w\n",
    "    return w, b\n",
    "\n",
    "# Convertendo labels para -1 e 1\n",
    "y_svm = np.where(y_train > np.median(y_train), 1, -1)\n",
    "\n",
    "# Treinando SVM\n",
    "w_svm, b_svm = sgd_svm(X_train, y_svm)\n",
    "\n",
    "# Predições\n",
    "y_train_pred_svm = np.sign(X_train.dot(w_svm) + b_svm)\n",
    "y_test_pred_svm = np.sign(X_test.dot(w_svm) + b_svm)\n",
    "\n",
    "# Erro\n",
    "train_error_svm = np.mean(y_train_pred_svm != y_svm)\n",
    "test_error_svm = np.mean(y_test_pred_svm != np.where(y_test > np.median(y_test), 1, -1))\n",
    "\n",
    "print(\"Erro de Treino SVM:\", train_error_svm)\n",
    "print(\"Erro de Teste SVM:\", test_error_svm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
